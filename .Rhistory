#  Step 1. Read and Prepare the data
#  Split the data - Training set and Validation set
########################################################################################
# import the CSV file
wbcd <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
str(wbcd) # Lets check what we have in this dataset
#First column is the randomly generated Patient ID
#Get rid of it
#wbcd <- wbcd[-1]
wbcd$id <- NULL
# table or proportions with more informative labels
table(wbcd$diagnosis)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
labels = c("Benign", "Malignant"))
#prop() calculates the proportion of a value or category in a variable
round(prop.table(table(wbcd$diagnosis)) * 100, 1)
# summarize three numeric features
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
#Given substantial scale differences, we need to normalize the data
#Convert all values on a 0 to 1 scale
#Function for Min-Max Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
#Applying normalization function to all columns except the response variable
wbcd_n <- as.data.frame(lapply(wbcd[2:ncol(wbcd)], normalize))
#Checking whether scale differences persist
summary(wbcd_n[c("radius_mean", "area_mean", "smoothness_mean")])
# Creating training and testing sets.
# Lets have 100 rows in test, rest in train
#Set a seed for random number generator for consistent output
set.seed(123)
#Selects 100 random rows for test data
test_set <- sample(1:nrow(wbcd_n), 100)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors
wbcd_train <- wbcd_n[-test_set, ]
wbcd_test <- wbcd_n[test_set, ]
#Now the response (aka Labels)
wbcd_train_labels <- wbcd[-test_set, "diagnosis"]
wbcd_test_labels <- wbcd[test_set, "diagnosis"]
#Lets run the KNN command
library(class)
library(caret)
#Run KNN on train data, create predictions for test data
#Starting K value close to sqrt(nrow(wbcd_train))
sqrt(nrow(wbcd_train))
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k=21)
#Evaluate model results
library(gmodels)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq=FALSE)
#True Positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.
#True Negatives (TN): We predicted no, and they don't have the disease.
#False Positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a "Type I error.")
#False Negatives (FN): We predicted no, but they actually do have the disease. (Also known as a "Type II error.")
# Accuracy: Overall, how often is the classifier correct?
(62 + 33) / (62 + 33 + 5 + 0)
# Error rate: Overall, how often is it wrong?
(5 + 0) / (62 + 33 + 5 + 0)
# error rate = 1 - accuracy
1 - 0.95
## Beyond accuracy: other performance measures ----
# Kappa statistic: This is essentially a measure of how well the classifier performed as compared to how well it would have performed simply by chance.
pr_a <- (0.62 + 0.33)
pr_a
pr_e <- 0.62*0.67 + 0.38*0.33
pr_e
k <- (pr_a - pr_e) / (1 - pr_e)
k
# Sensitivity: When it's actually yes, how often does it predict yes?
sens <- 33 / (33 + 5)
sens
# Specificity: When it's actually no, how often does it predict no?
spec <- 62 / (62 + 0)
spec
# Precision: When it predicts yes, how often is it correct?
prec <- 33 / (33 + 0)
prec
# example using the caret package
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
#Using Z-Score Normalization
wbcd_z <- as.data.frame(scale(wbcd[2:ncol(wbcd)]))
wbcd_train <- wbcd_z[-test_set, ]; wbcd_test <- wbcd_z[test_set, ]
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k=21)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq=FALSE)
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
# Partioning Data Randomly using caret, 70% in train
set.seed(567)
in_train <- createDataPartition(wbcd$diagnosis, p = 0.7, list = FALSE)
wbcd_train <- wbcd_n[in_train, ]
wbcd_test <- wbcd_n[-in_train, ]
wbcd_train_labels <- wbcd[in_train, "diagnosis"]
wbcd_test_labels <- wbcd[-in_train, "diagnosis"]
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k=21)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq=FALSE)
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
# Put alc_consumption data in its own object
alc_consumption <- con["alc"]
# Remove "alc" from initial data set
# con$alc <- NULL
# Make a copy of the data before Z-score normalization to prevent future issues
data_lg <- con
# Make a copy of data set in preparation for logistic regression
# Make a copy of the data before Z-score normalization to prevent future issues
# data_lg <- con
# Put outcome in its own object
alc_outcome <- alc_consumption
# Remove "alc" from initial data set
# data_lg$alc <- NULL
# Set a seed for random number generator for consistent output
set.seed(567)
# Split the data into training and testing sets
# Partition 70% of the data into the training set and the remaining 30% in the testing set.
sample_size <- floor(0.70 * nrow(data_lg))
training_index <- sample(seq_len(nrow(data_lg)), size = sample_size)
# Create training and testing sets
lg_pred_train <- data_lg[training_index,]
lg_pred_test <- data_lg[-training_index,]
# Split outcome variable into training and testing sets using the same partition as above.
alc_outcome_train <- alc_outcome[training_index,]
alc_outcome_test <- alc_outcome[-training_index,]
#initial_model = glm(Survived ~ ., data = titanic, family = "binomial")
#summary(initial_model)
lg_results <- glm(alc ~ ., data = data_lg, family = "binomial")
setwd("~/Winter 2022/TO 414 001 WN 2022/HW #3 - Predicting Alcoholism")
data_lg <- read.csv("spor.csv")
# Convert multiple variables to factors
data_lg[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(data_lg[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], factor)
# Convert all categorical variables to numeric variables
data_lg[sapply(data_lg, is.factor)] <- data.matrix(data_lg[sapply(data_lg, is.factor)])
data_lg{"alc"}
data_lg["alc"]
class(data_lg["age"])
class(data_lg["alc"])
class(data_lg$alc)
# Put outcome in its own object
alc_outcome <- data_lg["alc"]
str(data_lg)
# Convert multiple variables to factors
con[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(con[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], factor)
# Convert all categorical variables to numeric variables
con[sapply(con, is.factor)] <- data.matrix(con[sapply(con, is.factor)])
str(con)
data_lg <- read.csv("spor.csv")
# Convert multiple variables to factors
data_lg[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(data_lg[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], factor)
str(data_lg)
data_lg <- read.csv("spor.csv")
str(data_lg)
# Convert multiple variables to factors
data_lg[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(data_lg[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], as.factor)
str(data_lg)
data_lg <- read.csv("spor.csv")
# Convert multiple variables to factors
data_lg[c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(data_lg[c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], as.factor)
str(data_lg)
data_lg <- read.csv("spor.csv")
# Convert multiple variables to factors
data_lg$school <- as.factor(data_lg$school)
data_lg$sex <- as.factor(data_lg$sex)
data_lg$address <- as.factor(data_lg$address)
data_lg$famsize <- as.factor(data_lg$famsize)
data_lg$Pstatus <- as.factor(data_lg$Pstatus)
data_lg$activities <- as.factor(data_lg$activities)
data_lg$romantic <- as.factor(data_lg$romantic)
data_lg$alc <- as.factor(data_lg$alc)
str(data_lg)
getwd()
setwd("~/Winter 2022/TO 414 001 WN 2022/HW #3 - Predicting Alcoholism")
data_lg <- read.csv("spor.csv")
str(data_lg)
data_lg$school <- as.factor(data_lg$school)
str(data_lg)
data_lg <- as.data.frame(unclass(data_lg), stringsAsFactors = TRUE)
str(data_lg)
data_lg <- read.csv("spor.csv")
data_lg <- as.data.frame(unclass(data_lg), stringsAsFactors = FALSE)
str(data_lg)
data_lg <- as.data.frame(unclass(data_lg), stringsAsFactors = TRUE)
str(data_lg)
table(data_lg$school)
# Convert All Character Columns of Data Frame to Factor
data_lg <- as.data.frame(unclass(data_lg), stringsAsFactors = TRUE)
# Factor alc
data_lg$alc <- as.factor(data_lg$alc)
data<- read.csv("spor.csv")
# Convert All Character Columns of Data Frame to Factor
data<- as.data.frame(unclass(data), stringsAsFactors = TRUE)
# Factor alc
data$alc <- as.factor(data$alc)
head(data)
str(data)
set.seed(123)
split <- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
split
table(split)
table(split)
454+194
648*0.7
train <- data[split == 0,]
head(train)
test <- data[split == 1,]
head(test)
dim(train)
dim(test)
data<- read.csv("spor.csv")
str(data)
summary(data)
# Convert All Character Columns of Data Frame to Factor
data<- as.data.frame(unclass(data), stringsAsFactors = TRUE)
# Factor alc
data$alc <- as.factor(data$alc)
# Set a seed for random number generator for consistent output
set.seed(123)
split <- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
# Verify split data
# 454 observations should be in the training data (i.e. 0), and 194 observations should be in the testing data (i.e. 1)
table(split)
# Create training data set
train <- data[split == 0,]
# Create testing data set
test <- data[split == 1,]
# https://www.r-bloggers.com/2021/12/how-to-split-data-into-train-and-test-in-r/
model = glm(alc ~ ., data = train, family = "binomial")
summary(model)
model <- glm(alc ~ ., data = train, family = "binomial")
summary(model)
model2 <- glm(alc ~ sex + Pstatus + studytime + famrel + goout + health + absences, data = train, family = "binomial")
summary(model2)
model3 <- glm(alc ~ sex + studytime + famrel + goout + health + absences, data = train, family = "binomial")
summary(model3)
FitStart <- glm(alc ~ 1, data = train, family = "binomial")
step(FitStart, direction = "both", scope = formula(FitAll))
FitStart <- glm(alc ~ 1, data = train, family = "binomial")
FitAll <- glm(alc ~ ., data = train, family = "binomial")
summary(model)
step(FitStart, direction = "both", scope = formula(FitAll))
FitAll <- glm(alc ~ ., data = train, family = "binomial")
summary(FitAll)
FitAllMinusNonSig <- glm(alc ~ sex + Pstatus + studytime + famrel + goout + health + absences, data = train, family = "binomial")
summary(FitAllMinusNonSig)
# Stepwise regression found a better model, i.e. it scored a 527.92 on the AIC scale
# The best model is alc ~ goout + sex + famrel + studytime + health + absences + Pstatus + freetime
bestModel <- glm(formula = alc ~ goout + sex + famrel + studytime + health + absences + Pstatus + freetime, family = "binomial", data = train)
results <- predict(bestModel, newdata = test)
library(gmodels)
results <- predict(bestModel, newdata = test)
CrossTable(x = results, y = bestModel, prop.chisq=FALSE)
library(gmodels)
library(caret)
library(kernlab)
library(gmodels)
library(caret)
results <- predict(bestModel, newdata = test)
confusionMatrix(results, test$alc)
results <- predict(bestModel, newdata = test)
confusionMatrix(results, test)
summary(results)
results
library(gmodels)
library(caret)
library(tidyverse)
results <- predict(bestModel, newdata = test, type = "response")
results
View(data)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.5, 1 , 0)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.5, 1 , 0)
table(results, alc)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.5, 1 , 0)
table(results, data$alc)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.5, 1 , 0)
table(results, test$alc)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.5, 1 , 0)
table(test$alc, results)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.5, 1 , 0)
table(test$alc, results)
CrossTable(x = test$alc, y = results,
prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.51, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.52, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.53, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.54, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.6, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
27+34
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.65, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
26+35
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.7, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.69, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.68, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.67, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.66, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.65, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
56 + 77
/194
133/194
133/194*100
49+121
170/195*100
56+77
133/194*100
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.1, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.65, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.20, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.30, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.40, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.50, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.60, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
27+34
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.60, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
confusionMatrix(test$alc, results)
test$alc
results
class(test$alc)
class(results)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.60, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
confusionMatrix(test$alc, as.factor(results)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.60, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
confusionMatrix(test$alc, as.factor(results))
knitr::opts_chunk$set(echo = TRUE)
CrossTable(x = alc_consumption_testing, y = con_pred_knn, prop.chisq=FALSE)
CrossTable(x = alc_consumption_testing, y = con_pred_knn, prop.chisq=FALSE)
CrossTable(x = alc_consumption_testing, y = con_pred_knn, prop.chisq=FALSE)
# Set a seed for random number generator for consistent output
set.seed(567)
# Split the data into training and testing sets
# Partition 70% of the data into the training set and the remaining 30% in the testing set.
sample_size <- floor(0.70 * nrow(con))
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.70, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
confusionMatrix(test$alc, as.factor(results))
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.75, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
confusionMatrix(test$alc, as.factor(results))
getwd()
knitr::opts_chunk$set(echo = TRUE)
library(gmodels)
library(caret)
CrossTable(x = alc_consumption_testing, y = con_pred_knn,
prop.chisq=FALSE)
confusionMatrix(alc_consumption_testing, con_pred_knn)
class
class(alc_consumption_testing)
class(con_pred_knn)
CrossTable(x = alc_consumption_testing, y = con_pred_knn,
prop.chisq=FALSE)
confusionMatrix(as.factor(alc_consumption_testing), con_pred_knn)
26+105
131/195*100
con_pred_knn <- knn(train = training_data_set, test = testing_data_set, k = neighbors_k)
library(class)
con_pred_knn <- knn(train = training_data_set, test = testing_data_set, k = neighbors_k)
CrossTable(x = alc_consumption_testing, y = con_pred_knn,
prop.chisq=FALSE)
#confusionMatrix(as.factor(alc_consumption_testing, con_pred_knn)
con_pred_knn <- knn(train = training_data_set, test = testing_data_set, cl = alc_consumption_training, k = neighbors_k)
library(gmodels)
library(caret)
CrossTable(x = alc_consumption_testing, y = con_pred_knn,
prop.chisq=FALSE)
#confusionMatrix(as.factor(alc_consumption_testing, con_pred_knn)
knitr::opts_chunk$set(echo = TRUE)
# Import data
data <- read.csv("spor.csv")
str(data)
summary(data)
# Convert multiple variables to factors
data[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(data[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], factor)
class(data)
# Import data
df <- read.csv("spor.csv")
str(df)
summary(df)
# Convert multiple variables to factors
df[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(df[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], factor)
# Convert all categorical variables to numeric variables
df[sapply(df, is.factor)] <- data.matrix(df[sapply(df, is.factor)])
# Import data
data <- read.csv("spor.csv")
str(data)
summary(data)
# Convert multiple variables to factors
data[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")] <- lapply(data[, c("school", "sex", "address", "famsize", "Pstatus", "activities", "romantic", "alc")], factor)
# Convert all categorical variables to numeric variables
data[sapply(data, is.factor)] <- data.matrix(data[sapply(data, is.factor)])
# Put consumption data in its own object
consumption <- data["alc"]
# Remove "alc" from initial data set
# con$alc <- NULL
# Make a copy of the data before Z-score normalization to prevent future issues
# data_lg <- con
str(data)
# z-Score Standardization
data[, c("age", "Medu", "Fedu", "studytime", "famrel", "freetime", "goout", "health", "absences", "grades")] <- scale(data[, c("age", "Medu", "Fedu", "studytime", "famrel", "freetime", "goout", "health", "absences", "grades")])
# z-Score Standardization
data[, c("age", "Medu", "Fedu", "studytime", "famrel", "freetime", "goout", "health", "absences", "grades")] <- scale(data[, c("age", "Medu", "Fedu", "studytime", "famrel", "freetime", "goout", "health", "absences", "grades")])
summary(data)
# Set a seed for random number generator for consistent output
set.seed(567)
# Split the data into training and testing sets
# Partition 70% of the data into the training set and the remaining 30% in the testing set.
sample_size <- floor(0.70 * nrow(data))
training_index <- sample(seq_len(nrow(data)), size = sample_size)
# Create training and testing sets
training_data_set <- data[training_index,]
testing_data_set <- data[-training_index,]
# Split dependent variable into training and testing sets using the same partition as above.
alc_consumption_training <- alc_consumption[training_index,]
alc_consumption_testing <- alc_consumption[-training_index,]
# -----------------------------------
# Partion data randomly using caret, 70% in train
# train_index <- createDataPartition(alc_consumption, p = 0.7, list = FALSE)
# wbcd_train <- wbcd_n[in_train, ]
# wbcd_test <- wbcd_n[-in_train, ]
# wbcd_train_labels <- wbcd[in_train, "diagnosis"]
# wbcd_test_labels <- wbcd[-in_train, "diagnosis"]
# Put consumption data in its own object
y <- data["alc"]
# Remove "alc" from initial data set
# con$alc <- NULL
# Make a copy of the data before Z-score normalization to prevent future issues
# data_lg <- con
# Set a seed for random number generator for consistent output
set.seed(567)
# Split the data into training and testing sets
# Partition 70% of the data into the training set and the remaining 30% in the testing set.
sample_size <- floor(0.70 * nrow(data))
training_index <- sample(seq_len(nrow(data)), size = sample_size)
# Create training and testing sets
train <- data[training_index,]
test <- data[-training_index,]
# Split dependent variable into training and testing sets using the same partition as above.
y_train <- y[training_index,]
y_test <- y[-training_index,]
# -----------------------------------
# Partion data randomly using caret, 70% in train
# train_index <- createDataPartition(alc_consumption, p = 0.7, list = FALSE)
# wbcd_train <- wbcd_n[in_train, ]
# wbcd_test <- wbcd_n[-in_train, ]
# wbcd_train_labels <- wbcd[in_train, "diagnosis"]
# wbcd_test_labels <- wbcd[-in_train, "diagnosis"]
knn_pred <- knn(train = train, test = test, cl = y_train, k = neighbors_k)
data<- read.csv("spor.csv")
str(data)
summary(data)
# Convert All Character Columns of Data Frame to Factor
data<- as.data.frame(unclass(data), stringsAsFactors = TRUE)
# Factor alc
data$alc <- as.factor(data$alc)
# Set a seed for random number generator for consistent output
set.seed(123)
split <- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
# Verify split data
# 454 observations should be in the training data (i.e. 0), and 194 observations should be in the testing data (i.e. 1)
table(split)
# Create training data set
train <- data[split == 0,]
# Create testing data set
test <- data[split == 1,]
# https://www.r-bloggers.com/2021/12/how-to-split-data-into-train-and-test-in-r/
# Build a model with y-intercept only
# To be used in stepwise regression
FitStart <- glm(alc ~ 1, data = train, family = "binomial")
# Build a model with all variables
FitAll <- glm(alc ~ ., data = train, family = "binomial")
summary(FitAll)
# Build a model after removing nonsignificant variables
FitAllMinusNonSig <- glm(alc ~ sex + Pstatus + studytime + famrel + goout + health + absences, data = train, family = "binomial")
summary(FitAllMinusNonSig)
# I believe the best model is alc ~ sex + Pstatus + studytime + famrel + goout + health + absences because it scored a 528.29 on the AIC scale
# Let's see if stepwise regression finds a better model
step(FitStart, direction = "both", scope = formula(FitAll))
# Stepwise regression found a better model, i.e. it scored a 527.92 on the AIC scale
# The best model is alc ~ goout + sex + famrel + studytime + health + absences + Pstatus + freetime
bestModel <- glm(formula = alc ~ goout + sex + famrel + studytime + health + absences + Pstatus + freetime, family = "binomial", data = train)
library(gmodels)
library(caret)
results <- ifelse(predict(bestModel, newdata = test, type = "response") > 0.60, 1 , 0)
CrossTable(x = test$alc, y = results, prop.chisq=FALSE)
confusionMatrix(test$alc, as.factor(results))
round(0.6856)
round(0.6856*100)
round(0.8718*100)
